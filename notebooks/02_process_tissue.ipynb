{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "931s5v0DCisY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbc5fd6a"
      },
      "source": [
        "# Task\n",
        "Analyze the spatial omics data using ontology mining techniques as described in the notebook \"02_ontology_mining.ipynb\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c14a8d4"
      },
      "source": [
        "## Data loading and preprocessing\n",
        "\n",
        "### Subtask:\n",
        "Load the spatial omics data and perform initial preprocessing steps. This may include normalization, scaling, or handling missing values, depending on the data format and the specific ontology mining techniques to be used.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40b853b5"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the spatial omics data from the specified file into an AnnData object and display its structure.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkeqvXOCtzEh",
        "outputId": "8854613c-52db-4a97-ef75-242f1faffbd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The path to your university folder will now be inside your personal mounted drive\n",
        "# via the shortcut you created.\n",
        "university_folder_path = '/content/drive/My Drive/Ovary'\n",
        "\n",
        "# You can now list the files inside it to verify\n",
        "import os\n",
        "print(os.listdir(university_folder_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekXtpR5Ht1f1",
        "outputId": "905e7c9b-f19a-4192-964e-68f8353ea588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['HBM539.JDPH.785', 'HBM853.LCNF.879']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import anndata as ad\n",
        "import scanpy as sc\n",
        "import squidpy as sq\n",
        "\n",
        "sc.logging.print_header()\n",
        "print(f\"squidpy=={sq.__version__}\")\n",
        "\n",
        "# The path to your university folder will now be inside your personal mounted drive\n",
        "# via the shortcut you created.\n",
        "university_folder_path = '/content/drive/My Drive/Ovary/HBM539.JDPH.785'\n",
        "\n",
        "# Assuming the spatial omics data is in .h5ad format within the specified folder\n",
        "# You might need to adjust the filename if it's different\n",
        "data_file_path = os.path.join(university_folder_path, 'expr.h5ad')\n",
        "\n",
        "try:\n",
        "    adata = ad.read_h5ad(data_file_path)\n",
        "    print(adata)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{data_file_path}' was not found.\")\n",
        "    print(\"Please make sure the filename and path are correct.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the data: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxv8-8aLt7Oj",
        "outputId": "a5ba83b1-80c7-43ec-9f7b-edbd9b4bfab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.11/importlib/__init__.py:126: FutureWarning: The legacy Dask DataFrame implementation is deprecated and will be removed in a future version. Set the configuration option `dataframe.query-planning` to `True` or None to enable the new Dask Dataframe implementation and silence this warning.\n",
            "  return _bootstrap._gcd_import(name[level:], package, level)\n",
            "/usr/local/lib/python3.11/dist-packages/cudf/utils/_ptxcompiler.py:64: UserWarning: Error getting driver and runtime versions:\n",
            "\n",
            "stdout:\n",
            "\n",
            "\n",
            "\n",
            "stderr:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 4, in <module>\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/cudadrv/driver.py\", line 314, in __getattr__\n",
            "    raise CudaSupportError(\"Error at driver init: \\n%s:\" %\n",
            "numba.cuda.cudadrv.error.CudaSupportError: Error at driver init: \n",
            "\n",
            "CUDA driver library cannot be found.\n",
            "If you are sure that a CUDA driver is installed,\n",
            "try setting environment variable NUMBA_CUDA_DRIVER\n",
            "with the file path of the CUDA driver shared library.\n",
            ":\n",
            "\n",
            "\n",
            "Not patching Numba\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/cudf/utils/gpu_utils.py:62: UserWarning: Failed to dlopen libcuda.so.1\n",
            "  warnings.warn(str(e))\n",
            "/usr/local/lib/python3.11/dist-packages/anndata/utils.py:434: FutureWarning: Importing read_text from `anndata` is deprecated. Import anndata.io.read_text instead.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "squidpy==1.6.5\n",
            "AnnData object with n_obs × n_vars = 4990 × 60286\n",
            "    obs: 'Tissue Coverage Fraction'\n",
            "    var: 'hugo_symbol'\n",
            "    uns: 'X_spatial_units', 'spatial'\n",
            "    obsm: 'X_spatial', 'X_spatial_gpr', 'spatial'\n",
            "    layers: 'spliced', 'spliced_unspliced_sum', 'unspliced'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cF-HJrsQuoab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cf9275b"
      },
      "source": [
        "Now that the data is loaded, we will perform initial preprocessing steps, including normalization, scaling, and handling missing values. We will use `scanpy` for these operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c981555d",
        "outputId": "c35cfc28-82b9-491c-d9eb-203cd20d48c9"
      },
      "source": [
        "# Basic filtering: Filter out genes with less than a certain number of counts or present in less than a certain number of cells\n",
        "# and cells with less than a certain number of genes or total counts.\n",
        "# The exact thresholds might need adjustment based on the specific dataset.\n",
        "sc.pp.filter_cells(adata, min_genes=200)\n",
        "sc.pp.filter_genes(adata, min_cells=3)\n",
        "\n",
        "# Normalization: Normalize total counts per cell\n",
        "sc.pp.normalize_total(adata, target_sum=1e4)\n",
        "\n",
        "# Logarithmize the data\n",
        "sc.pp.log1p(adata)\n",
        "\n",
        "# Handle missing values (if any). AnnData and scanpy are generally designed to handle matrices without explicit missing values\n",
        "# but if there are NaNs or Infs, you might need to handle them.\n",
        "# For example, you could check for and replace them:\n",
        "# if np.any(np.isnan(adata.X)):\n",
        "#     adata.X[np.isnan(adata.X)] = 0  # Replace NaN with 0, or another appropriate value\n",
        "# if np.any(np.isinf(adata.X)):\n",
        "#      adata.X[np.isinf(adata.X)] = np.max(adata.X[np.isfinite(adata.X)]) # Replace Inf with max finite value\n",
        "\n",
        "# Scaling: Scale each gene to have unit variance and zero mean.\n",
        "# This is often done after logarithmizing, but before further analysis like PCA.\n",
        "sc.pp.scale(adata, max_value=10)\n",
        "\n",
        "print(\"Preprocessing complete.\")\n",
        "print(adata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: adata.X seems to be already log-transformed.\n",
            "Preprocessing complete.\n",
            "AnnData object with n_obs × n_vars = 0 × 0\n",
            "    obs: 'Tissue Coverage Fraction', 'n_genes'\n",
            "    var: 'hugo_symbol', 'n_cells', 'mean', 'std'\n",
            "    uns: 'X_spatial_units', 'spatial', 'log1p'\n",
            "    obsm: 'X_spatial', 'X_spatial_gpr', 'spatial'\n",
            "    layers: 'spliced', 'spliced_unspliced_sum', 'unspliced'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/scanpy/preprocessing/_utils.py:31: RuntimeWarning: Mean of empty slice.\n",
            "  return X.mean(axis=axis, dtype=dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Save the adata into a folder in the Drive\n",
        "\n",
        "# Define the output directory within your Drive\n",
        "output_directory_path = os.path.join(university_folder_path, 'processed_data')\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(output_directory_path, exist_ok=True)\n",
        "\n",
        "# Define the full path for the processed AnnData file\n",
        "processed_adata_path = os.path.join(output_directory_path, 'processed_expr.h5ad')\n",
        "\n",
        "# Save the processed adata object\n",
        "adata.write(processed_adata_path)\n",
        "\n",
        "print(f\"Processed AnnData saved to: {processed_adata_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joZOUfkPu9RV",
        "outputId": "fb205b8b-e12c-4b7a-83fa-dc2512f076fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed AnnData saved to: /content/drive/My Drive/Ovary/processed_data/processed_expr.h5ad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du8aUVShyr0P",
        "outputId": "eb17ac72-8483-4ada-95d6-e9ff91ad0705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "trQPDzKWzvOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce95715a"
      },
      "source": [
        "Alternatively, you can save the processed AnnData object to the local Colab environment. You can then download it from the Colab file explorer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5b6b8d3",
        "outputId": "b1421d07-2200-4aab-df9e-ef96fc45bdb3"
      },
      "source": [
        "# Define the path to save the processed AnnData file in the local Colab environment\n",
        "local_processed_adata_path = 'processed_expr.h5ad'\n",
        "\n",
        "# Save the processed adata object to the local environment\n",
        "adata.write(local_processed_adata_path)\n",
        "\n",
        "print(f\"Processed AnnData saved to: {local_processed_adata_path}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed AnnData saved to: processed_expr.h5ad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bV_N1X6E6H1B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}